
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">

  <head>
    <title>hw5.html</title>
  </head>

  <meta name="KEYWORDS" content="..." />
  <meta name="AUTHOR" content="Wang Xiahao" />

  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="http://www.ivo-welch.info/teaching/hw.css" />
  

  <body>

    <h1> Homework 5, by Wang xiahao, Feb 19th, 2019 </h1>

    <h2> Executive Summary </h2>

    <p> The purpose of the assignment is to compare my data from HW2 and HW3 with another student in class. I exchanged my data with Harry Yanxiang Zhao's and also discussed on our approach to solve the problems. The two datasets are not exactly the same as we chose different range and scope. 
    </p>

<b>NOTE: Internet connection is required to view the full page with diagram and css template</b>
     <h2> Summary of the result</h2>
     <h3>Homework 2</h3>
      <p>
    For homework 2, Harry has 566 stocks returns from 2010/01/04 to 2019/06/29 and 11918 entries in total while I have 452 stocks from 2011/01/03 to 2017/12/29 and 10926 entries in total. This is due to how we downloaded the dataset for S&P 500 differently. 
    I looked up on wiki and identified the S&P 500 firms at this moment while Harry went extra miles to identify the S&P 500 firms at the end of each year. Hence the he has a bigger resulting dataset. However, by eyeballing the resulting datasets, the different is insignificant and we both were able to conclude that equity return will decrease sharply on the ex-div date. 
    One quick solution for reconciliation is to merge the data and identify the entries that are common. Harry spearheaded on this effort and obtained the result in the following table. The conclusion does not change at all after the reconciliation.
    </p> 

     <table>
        <thead> 
          <tr> 
            <th>  </th> 
             <th> Mine </th> 
            <th> Harry</th> 
            <th> Reconciled Data</th> 
          </tr> </thead>
        <tbody>
          <tr> <td>Mean</td> <td>-0.004458</td><td>-0.004829</td><td>-0.004556</td></tr>
          <tr> <td>StdDev</td> <td>0.01909</td><td>0.01681</td><td>0.01644</td></tr>
          <tr> <td>Total entries</td> <td>10926</td><td>11918</td><td>9401</td></tr>
          <tr> <td>Total number of stocks</td> <td>452</td><td>566</td><td>418</td></tr>
          <tr> <td>Start Date</td> <td>1/3/2011</td><td>1/4/2011</td><td>1/3/2011</td></tr>
          <tr> <td>End Date</td> <td>12/29/2017</td><td>6/29/2019</td><td>12/29/2017</td></tr>
        </tbody>
      </table>
      <p><h3>The diagram below shows excess return from -20 to +20 days</h3></p>
      <p><img src="https://raw.githubusercontent.com/paragonhao/corporateFinance/master/HW5/HW5-1.png" alt="result"></p>
       <h3>Lesson learnt from Homework 2</h3>
    <p>Harry's approach is more reasonable than mine as he collected all the S&P500 firms cummulatively over the years. Next time I shall try to include more data that are within the scope of the reasearch. As for the code, both of us used libraries such as lubridate and data.table for data cleansing and manipulaition. Also credits to Harry on this one as he was the first person to introduce me R libraries such as lubridate and data.table at the beginning of the program :).
    </p>
   
     <h3>Homework 3</h3>
     <p>Again, discrepencies have occured in terms dataset that we used for this homework. Harry used the entire dataset from 1926 to 2018. While I only used data from 2010 to 2018. Hence, Harry's dataset almost entirely covers my dataset. Same approach is used to merge and reconcile data by carving out data in common.  The end result in shown in the table below. </p>

      <table>
        <thead> 
          <tr> 
            <th>  </th> 
             <th> Mine </th> 
            <th> Harry</th> 
            <th> Reconciled Data</th> 
          </tr> </thead>
        <tbody>
          <tr> <td>Mean</td> <td>0.1222061</td><td>0.153058</td><td>0.1282787</td></tr>
          <tr> <td>StdDev</td> <td>0.55326</td><td>0.82266</td><td>0.55469</td></tr>
          <tr> <td>Total entries</td> <td>73</td><td>1392</td><td>72</td></tr>
          <tr> <td>Total number of stocks</td> <td>99</td><td>566</td><td>10</td></tr>
          <tr> <td>Start Date</td> <td>2010</td><td>1926</td><td>2010</td></tr>
          <tr> <td>End Date</td> <td>2018</td><td>2018</td><td>2018</td></tr>
        </tbody>
      </table>
      <p>This reconciled result however, is not meaningful to showcase the return and volatility of the stock market. As I have only included data after 2010. The stock market has been on a steady growth after in financial crisis in 2008. This kind of explains why my volatility is much lower than that in Harry's dataset, which includes numerous financial crsises like great depression, black monday, dotcom bubble and 2008. </p>  

    <h3>Lesson learnt from Homework 3</h3>
    <p>Harry's approach is more reasonable than mine as he included a longer time horizon to study the volatility and return of the market. I should have included a longer time horizon in order to better capture the metrics from the markets.
    </p>
  
    <h2> Implementation </h2>
    <p>Implementation in R code can be found at my github <a href="https://github.com/paragonhao/corporateFinance/blob/master/HW5/hw5.r">here</a></p>

    <h2> References </h2>

    <ul>
      <li> <a href="https://wrds-web.wharton.upenn.edu/wrds/">WRDS</a>,WRDS, retrieved on 8th Feb, 2019. </li>
      <li> <a href="https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard">Global Industry Classification Standard</a>, retrieved on 8th Feb, 2019. </li>
    </ul>
      
    <p class="notice">TAs, please do not judge me too harshly.</p>

  </body>

</html>
